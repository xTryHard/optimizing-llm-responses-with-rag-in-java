# üõ†Ô∏è Optimizando respuestas de LLMs con Generaci√≥n Aumentada por Recuperaci√≥n (RAG) en Java

Los modelos de lenguaje de gran tama√±o (LLMs, por sus siglas en ingl√©s de ‚ÄúLarge Language Models‚Äù) son muy potentes, pero tienen dificultades para manejar informaci√≥n en tiempo real y, con frecuencia, generan respuestas err√≥neas o ‚Äúalucinaciones‚Äù.
En este taller pr√°ctico aprender√°s c√≥mo potenciar tu chatbot, basado en un LLM, mediante Generaci√≥n Aumentada por Recuperaci√≥n (RAG - Retrieval Augmented Generation) utilizando Java y SpringAI.


# Configura tu entorno local

Aqu√≠ est√°n las instrucciones para ejecutar el taller localmente.

## üß∞ Requisitos T√©cnicos

### üîß Hardware (recomendado)
- Memoria RAM: 16 GB
- Almacenamiento disponible: 25 GB libres
- Conectividad: acceso a Internet (Wi-Fi)

### üíª Software
- [Docker Desktop](https://www.docker.com/products/docker-desktop/) instalado y funcionando con al menos 4GB de memoria asignada.
- Imagen de Docker de [Ollama](https://hub.docker.com/r/ollama/ollama)
- Java Development Kit (JDK) 21 ([Oracle](https://www.oracle.com/java/technologies/javase/jdk21-archive-downloads.html), [SDKMAN!](https://sdkman.io/jdks/))
- Un IDE de preferencia (Se sugiere [IntelliJ IDEA](https://www.jetbrains.com/idea/))
- [Git](https://git-scm.com/)

### üåê Otros
- Cuenta activa en [GitHub](https://github.com/)


## üöÄ Inicializaci√≥n del Entorno con Docker Compose

Usaremos Docker Compose para levantar todos los servicios necesarios con un solo comando. El archivo docker-compose.yaml en la ra√≠z del proyecto se encargar√° de todo.

1. Iniciar los servicios: Abre una terminal en la ra√≠z del proyecto (donde se encuentra el archivo docker-compose.yaml) y ejecuta el siguiente comando:

```shell
  docker-compose up -d
```
Este comando crear√° e iniciar√° dos contenedores en segundo plano (-d):
- `ollama`: El servidor para los modelos de lenguaje (LLM). La primera vez que se ejecute, descargar√° autom√°ticamente el modelo `qwen3:1.7b-q4_K_M`. __¬°Ten paciencia, este paso puede tardar varios minutos dependiendo de tu conexi√≥n a internet!__
- `optimizing-with-rag-db`: La base de datos PostgreSQL con la extensi√≥n `pgvector` que usaremos para los ejercicios de RAG.

2. Verificar que los contenedores est√°n corriendo: Puedes verificar que ambos servicios se est√°n ejecutando con el comando:
```shell
  docker-compose ps
```

Deber√≠as ver ambos servicios (ollama y optimizing-with-rag-db) con el estado running o up

## Ejecutar el taller

Estos comandos se pueden ejecutar tantas veces como sea necesario para completar los pasos del taller.

(Opcional) Reiniciar la instancia de Ollama.
```shell
  docker-compose up -d
```

Construir la aplicaci√≥n
`./mvnw clean install`

Ejecutar la aplicaci√≥n
`./mvnw spring-boot:run`