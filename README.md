# 🛠️ Optimizando respuestas de LLMs con Generación Aumentada por Recuperación (RAG) en Java

Los modelos de lenguaje de gran tamaño (LLMs, por sus siglas en inglés de “Large Language Models”) son muy potentes, pero tienen dificultades para manejar información en tiempo real y, con frecuencia, generan respuestas erróneas o “alucinaciones”.
En este taller práctico aprenderás cómo potenciar tu chatbot, basado en un LLM, mediante Generación Aumentada por Recuperación (RAG - Retrieval Augmented Generation) utilizando Java y SpringAI.


## 🧰 Requisitos Técnicos

### 🔧 Hardware (recomendado)
- Memoria RAM: 16 GB
- Almacenamiento disponible: 25 GB libres
- Conectividad: acceso a Internet (Wi-Fi)

### 💻 Software
- [Docker Desktop](https://www.docker.com/products/docker-desktop/) instalado y funcionando
- Imagen de Docker de [Ollama](https://hub.docker.com/r/ollama/ollama)
- Java Development Kit (JDK) 21 ([Oracle](https://www.oracle.com/java/technologies/javase/jdk21-archive-downloads.html), [SDKMAN!](https://sdkman.io/jdks/))
- Un IDE de preferencia (Se sugiere [IntelliJ IDEA](https://www.jetbrains.com/idea/))
- [Git](https://git-scm.com/)
- [Node.js](https://nodejs.org/en) (>= v18) 

### 🌐 Otros
- Cuenta activa en [GitHub](https://github.com/)
