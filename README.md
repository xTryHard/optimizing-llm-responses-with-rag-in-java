# ğŸ› ï¸ Optimizando respuestas de LLMs con GeneraciÃ³n Aumentada por RecuperaciÃ³n (RAG) en Java

Los modelos de lenguaje de gran tamaÃ±o (LLMs, por sus siglas en inglÃ©s de â€œLarge Language Modelsâ€) son muy potentes, pero tienen dificultades para manejar informaciÃ³n en tiempo real y, con frecuencia, generan respuestas errÃ³neas o â€œalucinacionesâ€.
En este taller prÃ¡ctico aprenderÃ¡s cÃ³mo potenciar tu chatbot, basado en un LLM, mediante GeneraciÃ³n Aumentada por RecuperaciÃ³n (RAG - Retrieval Augmented Generation) utilizando Java y SpringAI.


## ğŸ§° Requisitos TÃ©cnicos

### ğŸ”§ Hardware (recomendado)
- Memoria RAM: 16 GB
- Almacenamiento disponible: 25 GB libres
- Conectividad: acceso a Internet (Wi-Fi)

### ğŸ’» Software
- [Docker Desktop](https://www.docker.com/products/docker-desktop/) instalado y funcionando
- Imagen de Docker de [Ollama](https://hub.docker.com/r/ollama/ollama)
- Java Development Kit (JDK) 21 ([Oracle](https://www.oracle.com/java/technologies/javase/jdk21-archive-downloads.html), [SDKMAN!](https://sdkman.io/jdks/))
- Un IDE de preferencia (Se sugiere [IntelliJ IDEA](https://www.jetbrains.com/idea/))
- [Git](https://git-scm.com/)
- [Node.js](https://nodejs.org/en) (>= v18) 

### ğŸŒ Otros
- Cuenta activa en [GitHub](https://github.com/)
