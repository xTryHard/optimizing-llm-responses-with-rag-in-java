# Configura tu entorno local

Aqu칤 est치n las instrucciones para ejecutar el taller localmente.

## 游빓 Requisitos T칠cnicos

### 游댢 Hardware (recomendado)
- Memoria RAM: 16 GB
- Almacenamiento disponible: 25 GB libres
- Conectividad: acceso a Internet (Wi-Fi)

### 游눹 Software
- [Docker Desktop](https://www.docker.com/products/docker-desktop/) instalado y funcionando con al menos 4GB de memoria asignada.
- Imagen de Docker de [Ollama](https://hub.docker.com/r/ollama/ollama)
- Java Development Kit (JDK) 21 ([Oracle](https://www.oracle.com/java/technologies/javase/jdk21-archive-downloads.html), [SDKMAN!](https://sdkman.io/jdks/))
- Un IDE de preferencia (Se sugiere [IntelliJ IDEA](https://www.jetbrains.com/idea/))
- [Git](https://git-scm.com/)

### 游깷 Otros
- Cuenta activa en [GitHub](https://github.com/)


## 游 Inicializaci칩n del Entorno con Docker Compose

Usaremos Docker Compose para levantar todos los servicios necesarios con un solo comando. El archivo docker-compose.yaml en la ra칤z del proyecto se encargar치 de todo.

1. Iniciar los servicios: Abre una terminal en la ra칤z del proyecto (donde se encuentra el archivo docker-compose.yaml) y ejecuta el siguiente comando:

```shell
  docker-compose up -d
```
Este comando crear치 e iniciar치 dos contenedores en segundo plano (-d):
- `ollama`: El servidor para los modelos de lenguaje (LLM). La primera vez que se ejecute, descargar치 autom치ticamente el modelo llama3.1. __춰Ten paciencia, este paso puede tardar varios minutos dependiendo de tu conexi칩n a internet!__
- `optimizing-with-rag-db`: La base de datos PostgreSQL con la extensi칩n `pgvector` que usaremos para los ejercicios de RAG.

2. Verificar que los contenedores est치n corriendo: Puedes verificar que ambos servicios se est치n ejecutando con el comando:
```shell
  docker-compose ps
```

Deber칤as ver ambos servicios (ollama y optimizing-with-rag-db) con el estado running o up

## Ejecutar el taller

Estos comandos se pueden ejecutar tantas veces como sea necesario para completar los pasos del taller.

(Opcional) Reiniciar la instancia de Ollama.
```shell
  docker-compose up -d
```

Construir la aplicaci칩n
```shell
  mvn clean install
```

Ejecutar la aplicaci칩n
```shell
  mvn spring-boot:run
```

[Go back](../../README.md)